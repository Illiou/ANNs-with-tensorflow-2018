{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "As an example we will try to learn the following function\n",
    "$$t = x^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need do create the dataset. \n",
    "training_data = [[1.0], [3.0], [4.0], [8.0]]\n",
    "training_labels = [[2.0], [6.0], [8.0], [16.0]]\n",
    "validation_data = [[5.0]]\n",
    "validation_labels = [[10.0]]\n",
    "\n",
    "# Before you start using tf functions it's useful to reset the graph. If you have to rerun cells start\n",
    "# with the first cell, in which you reset.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Now we use the tf.data library to create a proper dataset that we can work with.\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((training_data, training_labels))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_data, validation_labels))\n",
    "\n",
    "# This allows us to directly define batchsize we want to use.\n",
    "training_batch_size = 2\n",
    "validation_batch_size = 1\n",
    "training_dataset = training_dataset.batch(training_batch_size)\n",
    "validation_dataset = validation_dataset.batch(validation_batch_size)\n",
    "\n",
    "# Shuffle the training data in each epoch.\n",
    "training_dataset = training_dataset.shuffle(buffer_size=4, reshuffle_each_iteration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tf.float32, tf.float32)\n",
      "(TensorShape([Dimension(None), Dimension(1)]), TensorShape([Dimension(None), Dimension(1)]))\n"
     ]
    }
   ],
   "source": [
    "# Next we need an iterator which will allow us to iterate throught the dataset.\n",
    "iterator = tf.data.Iterator.from_structure(training_dataset.output_types,\n",
    "                                           training_dataset.output_shapes)\n",
    "\n",
    "# We can easily access different properties of the dataset.\n",
    "print(training_dataset.output_types)\n",
    "print(training_dataset.output_shapes)\n",
    "\n",
    "# There is a method that returns always the next element from the iterator.\n",
    "# Let's give it a name.\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "# Later on we also need to initialize the iterator and load a dataset into it.\n",
    "training_init_op = iterator.make_initializer(training_dataset)\n",
    "validation_init_op = iterator.make_initializer(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1)\n"
     ]
    }
   ],
   "source": [
    "# Now we can already proceed and design our model.\n",
    "\n",
    "\n",
    "\n",
    "# The output of the iterator.get_next() method will return a list\n",
    "# with the first entry being the input data and the second being the labels of the batch.\n",
    "input_data = next_batch[0]\n",
    "labels = next_batch[1]\n",
    "\n",
    "# You can print the shapes of tensors!\n",
    "print(input_data.shape)\n",
    "\n",
    "# As our model is only simply linear function we only need one weight to approximate it.\n",
    "weight = tf.Variable(0.5, dtype=tf.float32)\n",
    "output = input_data * weight\n",
    "\n",
    "# Now we need to define the loss that we want to minimize. We use Mean Squared Error\n",
    "mse = 0.5 * tf.reduce_sum(tf.square(labels - output))\n",
    "loss = tf.reduce_mean(mse)\n",
    "\n",
    "# Last but not least we need the optimizer that minimizes our loss.\n",
    "# For this we need first a learning rate.\n",
    "learning_rate = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "# And tell the optimizer what iat should optimize.\n",
    "training_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 11.25\n",
      "Training loss: 72.9000015258789\n",
      "Validation loss: 0.9112505316734314\n",
      "Training loss: 2.9160022735595703\n",
      "Training loss: 0.014580029994249344\n",
      "Validation loss: 0.029524507001042366\n",
      "Training loss: 0.09447824209928513\n",
      "Training loss: 0.0004723923630081117\n",
      "Validation loss: 0.0009565639775246382\n",
      "Training loss: 0.003061054740101099\n",
      "Training loss: 1.530673398519866e-05\n",
      "Validation loss: 3.0996277928352356e-05\n",
      "Training loss: 1.2397948012221605e-05\n",
      "Training loss: 8.033370249904692e-05\n",
      "Validation loss: 1.0041712812380865e-06\n",
      "Training loss: 3.2144293982128147e-06\n",
      "Training loss: 1.6099193089758046e-08\n",
      "Validation loss: 3.26617737300694e-08\n",
      "Training loss: 1.0412804840598255e-07\n",
      "Training loss: 5.182130280445563e-10\n",
      "Validation loss: 1.0477378964424133e-09\n",
      "Training loss: 4.2457060089873266e-10\n",
      "Training loss: 2.7063151719630696e-09\n",
      "Validation loss: 3.6834535421803594e-11\n",
      "Training loss: 1.27613475342514e-11\n",
      "Training loss: 9.606537787476555e-11\n",
      "Validation loss: 1.8189894035458565e-12\n",
      "Training loss: 5.186961971048731e-13\n",
      "Training loss: 5.115907697472721e-12\n",
      "Validation loss: 4.547473508864641e-13\n"
     ]
    }
   ],
   "source": [
    "# Define for how many epochs you want to train.\n",
    "epochs = 10\n",
    "\n",
    "# Let's train our model.\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # First initialize the variables.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Now we set up a loop that will run until we finished all epochs.\n",
    "    for _ in range(epochs):\n",
    "         \n",
    "        # TRAINING\n",
    "        # Load the training data into the iterator.\n",
    "        sess.run(training_init_op)\n",
    "        \n",
    "        # In each epoch we want to go through all batches of the training data. \n",
    "        while True:\n",
    "            try:\n",
    "                _, loss_value = sess.run((training_step, loss))\n",
    "                # For monitoring we print the loss value.\n",
    "                print(\"Training loss: {}\".format(loss_value))\n",
    "            \n",
    "            # Breakout of the loop if we looked at all batches\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "                \n",
    "        # VALIDATION\n",
    "        # Load the validation data into the iterator.\n",
    "        sess.run(validation_init_op)\n",
    "        # Usually we can put all of the validation data in one batch. We don't need a loop here!\n",
    "        loss_value = sess.run((loss))\n",
    "        # For monitoring print it.\n",
    "        print(\"Validation loss: {}\".format(loss_value))\n",
    "        \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
