{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 Group 7\n",
    "\n",
    "- First download the MNIST dataset from http://yann.lecun.com/exdb/mnist/ and put it in a folder called MNIST on the same level as this notebook (or change the base_path under `data preparation and visualization` to the folder where you saved the dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import struct\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General tensorflow settings\n",
    "config = tf.ConfigProto()\n",
    "# Use GPU in incremental mode (is ignored on CPU version)\n",
    "config.gpu_options.allow_growth=True\n",
    "# Add config=config in every tf.Session() -> tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to read the data\n",
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 28, 28)\n",
      "Training labels shape: (60000,)\n",
      "Validation data shape: (10000, 28, 28)\n",
      "Validation labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Read all training and validation data\n",
    "base_path = './MNIST/'\n",
    "\n",
    "# Read training data and labels\n",
    "training_data = read_idx('{}train-images.idx3-ubyte'.format(base_path))\n",
    "training_labels = read_idx('{}train-labels.idx1-ubyte'.format(base_path))\n",
    "\n",
    "# Read validation data and labels\n",
    "validation_data = read_idx('{}t10k-images.idx3-ubyte'.format(base_path))\n",
    "validation_labels = read_idx('{}t10k-labels.idx1-ubyte'.format(base_path))\n",
    "\n",
    "\n",
    "# Print some information about the data\n",
    "print('Training data shape: {}'.format(training_data.shape))\n",
    "print('Training labels shape: {}'.format(training_labels.shape))\n",
    "\n",
    "print('Validation data shape: {}'.format(validation_data.shape))\n",
    "print('Validation labels shape: {}'.format(validation_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the first 10 images from the training data set\n",
    "\n",
    "# Create a figure with 10 subplots\n",
    "fig, ax = plt.subplots(1, 10, figsize=(10,10))\n",
    "\n",
    "# Loop over the 10 subplots and print the corresponding image\n",
    "for i in range(10):\n",
    "    # Get the corresponing label and set it as the title of the plot\n",
    "    ax[i].set_title(training_labels[i])\n",
    "    # Show the image with grayscale colormap\n",
    "    ax[i].imshow(training_data[i], cmap=\"gray\")\n",
    "    # Turn axis labeling off\n",
    "    ax[i].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset for tensorflow\n",
    "\n",
    "# First we reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Now we use the tf.data library to create a tensorflow dataset\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((training_data, training_labels))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_data, validation_labels))\n",
    "\n",
    "# Now we specifiy the respective batch sizes\n",
    "training_batch_size = 128\n",
    "validation_batch_size = 10000\n",
    "training_dataset = training_dataset.batch(training_batch_size)\n",
    "validation_dataset = validation_dataset.batch(validation_batch_size)\n",
    "\n",
    "# Shuffle the training data in each epoch.\n",
    "training_dataset = training_dataset.shuffle(buffer_size=128, reshuffle_each_iteration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the iterator \n",
    "\n",
    "# First we create the iterator\n",
    "iterator = tf.data.Iterator.from_structure(training_dataset.output_types,\n",
    "                                           training_dataset.output_shapes)\n",
    "\n",
    "# We name the get_next method of the iterator to use it as a shortcut\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "# We prepare the initializer operations for both the training and the validation dataset\n",
    "training_init_op = iterator.make_initializer(training_dataset)\n",
    "validation_init_op = iterator.make_initializer(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/cRjXO96.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will format the data in the correct way\n",
    "\n",
    "# We define our input data and the corresponding labels\n",
    "input_data = next_batch[0]\n",
    "labels = tf.cast(next_batch[1], dtype=tf.int64)\n",
    "\n",
    "# We reshape our data\n",
    "# The first dimension (batch_size) stays the same and the second and third dimension collapses to one dimension\n",
    "input_data = tf.reshape(input_data, shape=[-1, 784])\n",
    "# We have to cast the data to float32 (from uint8)\n",
    "input_data = tf.cast(input_data, dtype=tf.float32)\n",
    "\n",
    "# We transform our labels to one hot vectors\n",
    "one_hot_labels = tf.one_hot(labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will define the forward step \n",
    "\n",
    "# First we will define the weights and the biases\n",
    "rands = tf.random_normal([784, 10], mean=0.0, stddev=2e-06)\n",
    "weights = tf.Variable(rands, dtype=tf.float32)\n",
    "\n",
    "biases = tf.Variable(tf.zeros(10), dtype=tf.float32)\n",
    "\n",
    "# Now we will mutiply the input with the weights to get the drive (logits)\n",
    "logits = input_data @ weights + biases\n",
    "\n",
    "# And use the softmax activation function\n",
    "output = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we have to define our metrics\n",
    "\n",
    "# Calculate the cross entropy\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=one_hot_labels, logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Define the accuracy\n",
    "match_bools = tf.equal(labels, tf.argmax(output, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(match_bools, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also have to define our optimizer\n",
    "\n",
    "# First we need to specify a learning rate \n",
    "learning_rate = 1e-5\n",
    "# Then we create an optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "# And tell the optimizer that it should minimize the loss\n",
    "training_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the end we will specify some summaries, so that we can visualize our progress with tensorboard\n",
    "\n",
    "# Specify the variables for the summaries\n",
    "tf.summary.scalar('loss', loss)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Now we will merge our two summary scalars\n",
    "merged_summaries = tf.summary.merge_all()\n",
    "\n",
    "# We also have two specify two summary file writers \n",
    "train_writer = tf.summary.FileWriter('./summaries/train/')\n",
    "validation_writer = tf.summary.FileWriter('./summaries/validation/', flush_secs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we can train our model\n",
    "\n",
    "# First we specify the number of epochs\n",
    "epochs = 5\n",
    "\n",
    "# We safely create our tensorflow session and pass our config parameters (for correct GPU usage, if GPU available)\n",
    "with tf.Session(config=config) as sess:\n",
    "    \n",
    "    # We initialize our variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # We define a step counter (for the summaries)\n",
    "    global_step = 0\n",
    "    \n",
    "    # We will run our training as often as specified in epochs\n",
    "    for _ in range(epochs):\n",
    "        \n",
    "        # Training Part\n",
    "        # We have to load the training data into the iterator\n",
    "        sess.run(training_init_op)\n",
    "        \n",
    "        # We have to loop over all our batches in every epoch\n",
    "        while True:\n",
    "            try:\n",
    "                # We train with one batch and read the summary and save it in the variable summary\n",
    "                _, summary = sess.run((training_step, merged_summaries))\n",
    "                \n",
    "                # We write the summary to the disk at the specified location\n",
    "                train_writer.add_summary(summary, global_step)\n",
    "                \n",
    "                # We update our step counter\n",
    "                global_step += 1\n",
    "                \n",
    "            # After we finished all batches, we catch the OutOfRangeErrpr and break\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "                \n",
    "        # Validation Part\n",
    "        # We have to load the validation data into the iterator\n",
    "        sess.run(validation_init_op)\n",
    "        # We read out the summary for the validation data (without training)\n",
    "        summary = sess.run(merged_summaries)\n",
    "        # And we save the summary to the disk\n",
    "        validation_writer.add_summary(summary, global_step) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization with TensorBoard:** \n",
    "- Run `tensorboard --logdir='./summaries'` in the terminal at the same location as this file. If the webbrowser does not start automatically, click on this link http://localhost:6006/ or on the link provided there\n",
    "- Alternatively, uncomment and run the cell below (wait for the training to finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir='./summaries'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
