{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6 Group 7\n",
    "- First download the dataset (\"bible.txt\") from Stud.IP and put it on the same level as this notebook\n",
    "\n",
    "## General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General tensorflow settings\n",
    "config = tf.ConfigProto()\n",
    "# Use GPU in incremental mode (is ignored on CPU version)\n",
    "config.gpu_options.allow_growth=True\n",
    "# Add config=config in every tf.Session() -> tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def tokenize_text(text):\n",
    "    text_lower = text.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text_tokenized = tokenizer.tokenize(text_lower)\n",
    "    return text_tokenized\n",
    "\n",
    "def create_dicts_from_tokenized_text(tokenized_text, vocabulary_size):\n",
    "    words_and_count = Counter(tokenized_text).most_common(vocabulary_size - 1)\n",
    "    # print(words_and_count)\n",
    "    word2id = {word: word_id for word_id, (word, _) in enumerate(words_and_count, 1)}\n",
    "    word2id[\"_UNKNOWN_\"] = 0\n",
    "    id2word = dict(zip(word2id.values(), word2id.keys()))\n",
    "    return word2id, id2word\n",
    "\n",
    "def find_and_print_nearest_neighbors(target_words, number_of_nearest_neighbors):\n",
    "    embedding_values = sess.run(embeddings)\n",
    "    normed_embeddings = embedding_values / np.sqrt(np.sum(embedding_values**2, axis=1, keepdims=True))\n",
    "    for word in target_words:\n",
    "        word_id = word2id[word]\n",
    "        word_embedding = normed_embeddings[word_id, :]\n",
    "        cosine_similarities = np.matmul(normed_embeddings, word_embedding )\n",
    "        n_nearest_neighbors = np.argsort(-cosine_similarities)[:number_of_nearest_neighbors]\n",
    "        print(\"Nearest to \" + word + \": \" + \", \".join([id2word[nearest] for nearest in n_nearest_neighbors]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_size = 64\n",
    "\n",
    "text = open('bible.txt').read()\n",
    "\n",
    "text_tokenized = tokenize_text(text)\n",
    "\n",
    "word2id, id2word = create_dicts_from_tokenized_text(text_tokenized, vocab_size)\n",
    "\n",
    "text_ids = [word2id.get(word, 0) for word in text_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "854033\n",
      "[1, 253, 447, 3, 161]\n",
      "[447, 447, 447, 447, 3, 3, 3, 3, 161, 161]\n",
      "[1, 253, 3, 161, 253, 447, 161, 193, 447, 3]\n",
      "3416116 3416116\n"
     ]
    }
   ],
   "source": [
    "print(len(text_ids))\n",
    "print(text_ids[:5])\n",
    "\n",
    "# Create the training and context words \n",
    "# Ignore the first two and the last two words, because they don't have a valid context\n",
    "context_words = []\n",
    "training_words = []\n",
    "for i in range(2, len(text_ids)-2):\n",
    "    for j in [-2,-1,1,2]:\n",
    "        training_words.append(text_ids[i])\n",
    "        context_words.append(text_ids[i+j])\n",
    "\n",
    "print(training_words[:10])\n",
    "print(context_words[:10])\n",
    "print(len(training_words), len(context_words))\n",
    "\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((training_words, context_words))\n",
    "training_dataset = training_dataset.shuffle(buffer_size=len(training_words), reshuffle_each_iteration=True)\n",
    "\n",
    "training_batch_size = 128\n",
    "training_dataset = training_dataset.batch(training_batch_size)\n",
    "\n",
    "# First we create the iterator\n",
    "iterator = tf.data.Iterator.from_structure(training_dataset.output_types,\n",
    "                                           training_dataset.output_shapes)\n",
    "\n",
    "# We name the get_next method of the iterator to use it as a shortcut\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "# We prepare the initializer operations for both the training and the validation dataset\n",
    "training_init_op = iterator.make_initializer(training_dataset)\n",
    "\n",
    "input_data = next_batch[0]\n",
    "input_goal = tf.expand_dims(next_batch[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext:0\", shape=(?,), dtype=int32) Tensor(\"ExpandDims:0\", shape=(?, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(input_data, input_goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding/embedding_lookup/Identity:0\", shape=(10000, 64), dtype=float32)\n",
      "<tf.Variable 'embedding/weight_matrix:0' shape=(10000, 64) dtype=float32_ref>\n",
      "<tf.Variable 'embedding/bias:0' shape=(10000,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"embedding\", reuse=tf.AUTO_REUSE) as scope:\n",
    "    uni_initializer = tf.random_uniform_initializer(-1.0, 1.0)\n",
    "    embedding_matrix = tf.get_variable(\"embedding_matrix\", [vocab_size, embedding_size], initializer=uni_initializer)\n",
    "    embeddings = tf.nn.embedding_lookup(embedding_matrix, np.arange(10000))\n",
    "    \n",
    "    norm_initializer = tf.truncated_normal_initializer(stddev=1.0/np.sqrt(embedding_size))\n",
    "    weight_matrix = tf.get_variable(\"weight_matrix\", [vocab_size, embedding_size], initializer=norm_initializer)\n",
    "    \n",
    "    bias_initializer = tf.constant_initializer(0)\n",
    "    biases = tf.get_variable(\"bias\", [vocab_size], initializer=bias_initializer)\n",
    "    \n",
    "    print(embeddings) \n",
    "    print(weight_matrix)\n",
    "    print(biases)\n",
    "    input_emb = tf.nn.embedding_lookup(embedding_matrix, input_data)\n",
    "    batch_losses = tf.nn.nce_loss(weight_matrix, biases, input_goal, input_emb, 64, vocab_size)\n",
    "    \n",
    "    loss = tf.reduce_mean(batch_losses)\n",
    "    \n",
    "    # Specify the variables for the summaries\n",
    "    tf.summary.scalar('loss', loss)\n",
    "\n",
    "    # Now we will merge our summary scalars\n",
    "    merged_summaries = tf.summary.merge_all()\n",
    "\n",
    "    # We also have too specify summary file writers \n",
    "    train_writer = tf.summary.FileWriter('./summaries/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before epoch: 0\n",
      "Nearest to israel: israel, persecutions, gittaim, sign, engraver, deeply, spirit, how\n",
      "Nearest to sin: sin, place, izehar, heaviness, aforetime, thirst, hatita, rump\n",
      "Nearest to god: god, solemnly, azzah, sheaf, oftentimes, poll, flourishing, moon\n",
      "Nearest to 5: 5, head, low, places, witchcrafts, reject, sodomite, transfigured\n",
      "Nearest to make: make, quietness, powerful, kid, whereof, ezer, uncle, corrupters\n",
      "Nearest to jesus: jesus, conceit, shimronites, confessed, stammering, passover, lancets, sell\n",
      "Nearest to year: year, additions, devices, and, winketh, striving, japhleti, saving\n",
      "\n",
      "Before epoch: 1\n",
      "Nearest to israel: israel, hanun, countries, village, judah, lords, darius, soweth\n",
      "Nearest to sin: sin, feared, place, heaviness, thirst, bilshan, rump, huntest\n",
      "Nearest to god: god, study, pardon, stirred, hear, 37, sheaf, difference\n",
      "Nearest to 5: 5, 8, 10, 21, 18, 13, 2, 20\n",
      "Nearest to make: make, give, do, hin, like, bring, quietness, burneth\n",
      "Nearest to jesus: jesus, finished, conceit, sell, shimronites, passover, frame, asahel\n",
      "Nearest to year: year, devices, additions, continue, riseth, amazed, ground, fowls\n",
      "\n",
      "Before epoch: 2\n",
      "Nearest to israel: israel, hanun, judah, countries, darius, telleth, village, lords\n",
      "Nearest to sin: sin, feared, thirst, bilshan, heaviness, place, huntest, rump\n",
      "Nearest to god: god, study, pardon, difference, stirred, hosts, tremble, lord\n",
      "Nearest to 5: 5, 6, 8, 10, 13, 2, 4, 20\n",
      "Nearest to make: make, give, bring, do, hin, selfwilled, agar, quietness\n",
      "Nearest to jesus: jesus, christ, conceit, finished, bereaved, frame, passover, amorites\n",
      "Nearest to year: year, devices, second, additions, continue, cana, amazed, captain\n",
      "\n",
      "Before epoch: 3\n",
      "Nearest to israel: israel, hanun, judah, telleth, countries, darius, lords, prospereth\n",
      "Nearest to sin: sin, thirst, bilshan, heaviness, huntest, feared, grasshopper, place\n",
      "Nearest to god: god, pardon, study, difference, hosts, stirred, tremble, lord\n",
      "Nearest to 5: 5, 6, 10, 4, 8, 3, 20, 13\n",
      "Nearest to make: make, give, bring, do, made, selfwilled, hap, quietness\n",
      "Nearest to jesus: jesus, christ, bereaved, scourged, conceit, paul, rejected, john\n",
      "Nearest to year: year, month, second, day, cana, additions, devices, continue\n",
      "\n",
      "Before epoch: 4\n",
      "Nearest to israel: israel, judah, hanun, telleth, darius, lords, midianitish, countries\n",
      "Nearest to sin: sin, thirst, huntest, meat, heaviness, sacrifice, feared, grasshopper\n",
      "Nearest to god: god, pardon, study, difference, tremble, hosts, kerchiefs, stirred\n",
      "Nearest to 5: 5, 3, 4, 6, 13, 10, 20, 8\n",
      "Nearest to make: make, give, bring, made, build, do, hap, selfwilled\n",
      "Nearest to jesus: jesus, christ, bereaved, scourged, john, paul, peter, amorites\n",
      "Nearest to year: year, month, day, cana, second, captain, additions, zur\n",
      "\n",
      "Before epoch: 5\n",
      "Nearest to israel: israel, judah, hanun, telleth, darius, lords, midianitish, gentle\n",
      "Nearest to sin: sin, meat, thirst, huntest, sacrifice, grasshopper, punishment, powerful\n",
      "Nearest to god: god, pardon, study, difference, hosts, tremble, contend, kerchiefs\n",
      "Nearest to 5: 5, 6, 3, 13, 4, 20, 8, 17\n",
      "Nearest to make: make, give, bring, made, build, hap, do, cause\n",
      "Nearest to jesus: jesus, christ, scourged, john, bereaved, peter, promise, paul\n",
      "Nearest to year: year, month, day, cana, captain, second, additions, twined\n",
      "\n",
      "Before epoch: 6\n",
      "Nearest to israel: israel, judah, hanun, midianitish, telleth, gentle, josiah, ammon\n",
      "Nearest to sin: sin, meat, thirst, huntest, punishment, sacrifice, grasshopper, rod\n",
      "Nearest to god: god, pardon, study, difference, tremble, hosts, kerchiefs, contend\n",
      "Nearest to 5: 5, 3, 6, 13, 4, 17, 14, 10\n",
      "Nearest to make: make, give, bring, made, build, hap, do, quietness\n",
      "Nearest to jesus: jesus, christ, scourged, promise, john, peter, paul, bereaved\n",
      "Nearest to year: year, month, day, captain, cana, second, twined, additions\n",
      "\n",
      "Before epoch: 7\n",
      "Nearest to israel: israel, judah, hanun, gentle, ammon, telleth, midianitish, amalek\n",
      "Nearest to sin: sin, meat, thirst, punishment, huntest, sacrifice, rod, state\n",
      "Nearest to god: god, pardon, study, difference, hosts, tremble, lord, kerchiefs\n",
      "Nearest to 5: 5, 6, 3, 4, 13, 17, 10, 8\n",
      "Nearest to make: make, give, made, bring, build, hap, cause, quietness\n",
      "Nearest to jesus: jesus, scourged, promise, john, peter, christ, paul, eliel\n",
      "Nearest to year: year, month, day, captain, cana, twined, second, additions\n",
      "\n",
      "Before epoch: 8\n",
      "Nearest to israel: israel, judah, hanun, ammon, gentle, josiah, jacob, telleth\n",
      "Nearest to sin: sin, meat, thirst, punishment, sacrifice, huntest, state, earnest\n",
      "Nearest to god: god, pardon, study, difference, hosts, kerchiefs, truth, tremble\n",
      "Nearest to 5: 5, 3, 6, 10, 17, 8, 4, 9\n",
      "Nearest to make: make, made, give, build, bring, hap, cause, quietness\n",
      "Nearest to jesus: jesus, promise, scourged, john, peter, christ, paul, eliel\n",
      "Nearest to year: year, month, day, captain, cana, twined, zur, second\n",
      "\n",
      "Before epoch: 9\n",
      "Nearest to israel: israel, judah, hanun, ammon, gentle, jacob, josiah, telleth\n",
      "Nearest to sin: sin, meat, thirst, punishment, sacrifice, reproach, huntest, earnest\n",
      "Nearest to god: god, pardon, study, hosts, difference, lord, kerchiefs, truth\n",
      "Nearest to 5: 5, 3, 6, 4, 14, 9, 8, 10\n",
      "Nearest to make: make, made, build, give, hap, bring, cause, pollute\n",
      "Nearest to jesus: jesus, promise, scourged, peter, john, eliel, adam, christ\n",
      "Nearest to year: year, month, day, captain, zur, cana, twined, additions\n",
      "\n",
      "Before epoch: 10\n",
      "Nearest to israel: israel, judah, hanun, ammon, gentle, jacob, josiah, syria\n",
      "Nearest to sin: sin, meat, punishment, thirst, reproach, sacrifice, earnest, trespass\n",
      "Nearest to god: god, pardon, study, hosts, difference, kerchiefs, lord, rash\n",
      "Nearest to 5: 5, 6, 3, 4, 17, 14, 9, 8\n",
      "Nearest to make: make, made, build, hap, give, bring, pollute, cover\n",
      "Nearest to jesus: jesus, promise, peter, scourged, john, adam, paul, eliel\n",
      "Nearest to year: year, month, day, captain, zur, cana, bulls, jewel\n",
      "\n",
      "Before epoch: 11\n",
      "Nearest to israel: israel, judah, ammon, hanun, jacob, gentle, josiah, amalek\n",
      "Nearest to sin: sin, meat, reproach, punishment, thirst, earnest, sacrifice, trespass\n",
      "Nearest to god: god, pardon, study, hosts, difference, kerchiefs, strength, rash\n",
      "Nearest to 5: 5, 6, 3, 4, 17, 14, 13, 2\n",
      "Nearest to make: make, made, build, give, hap, bring, cover, pollute\n",
      "Nearest to jesus: jesus, promise, peter, john, scourged, adam, eliel, paul\n",
      "Nearest to year: year, month, day, captain, zur, jewel, bulls, dividing\n",
      "\n",
      "Before epoch: 12\n",
      "Nearest to israel: israel, judah, hanun, ammon, jacob, josiah, syria, gentle\n",
      "Nearest to sin: sin, meat, reproach, punishment, earnest, thirst, trespass, sacrifice\n",
      "Nearest to god: god, pardon, study, hosts, kerchiefs, strength, difference, ancestors\n",
      "Nearest to 5: 5, 3, 6, 17, 14, 13, 10, 11\n",
      "Nearest to make: make, made, build, hap, establish, give, cover, bring\n",
      "Nearest to jesus: jesus, promise, john, adam, peter, scourged, eliel, paul\n",
      "Nearest to year: year, month, day, captain, jewel, bulls, zur, dividing\n",
      "\n",
      "Before epoch: 13\n",
      "Nearest to israel: israel, judah, hanun, ammon, jacob, gentle, telleth, syria\n",
      "Nearest to sin: sin, meat, reproach, punishment, trespass, earnest, thirst, sacrifice\n",
      "Nearest to god: god, pardon, study, hosts, difference, kerchiefs, strength, truth\n",
      "Nearest to 5: 5, 3, 4, 6, 17, 13, 14, 11\n",
      "Nearest to make: make, made, build, hap, establish, cover, give, pollute\n",
      "Nearest to jesus: jesus, promise, adam, peter, scourged, john, eliel, abimelech\n",
      "Nearest to year: year, month, day, captain, jewel, bulls, hour, dividing\n",
      "\n",
      "Before epoch: 14\n",
      "Nearest to israel: israel, judah, jacob, ammon, hanun, josiah, gentle, syria\n",
      "Nearest to sin: sin, meat, reproach, punishment, trespass, earnest, thirst, sacrifice\n",
      "Nearest to god: god, pardon, study, hosts, kerchiefs, difference, strength, truth\n",
      "Nearest to 5: 5, 3, 17, 4, 6, 14, 10, 8\n",
      "Nearest to make: make, made, build, hap, establish, cover, pollute, give\n",
      "Nearest to jesus: jesus, peter, adam, promise, scourged, john, eliel, abimelech\n",
      "Nearest to year: year, month, day, captain, jewel, hour, dividing, bulls\n"
     ]
    }
   ],
   "source": [
    "# First we specify the number of epochs\n",
    "epochs = 15\n",
    "\n",
    "# We safely create our tensorflow session and pass our config parameters (for correct GPU usage, if GPU available)\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    # We initialize our variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # We define a step counter (for the summaries)\n",
    "    global_steps = 0\n",
    "\n",
    "    # We will run our training as often as specified in epochs\n",
    "    for ep in range(epochs):\n",
    "\n",
    "        # Training Part\n",
    "        # We have to load the training data into the iterator\n",
    "        sess.run(training_init_op) \n",
    "        # Validation Part\n",
    "        print(\"\\nBefore epoch: {}\".format(ep))\n",
    "        find_and_print_nearest_neighbors([\"israel\", \"sin\", \"god\", \"5\", \"make\", \"jesus\", \"year\"], 8)\n",
    "        #find_and_print_nearest_neighbors([\"israel\"], 8)\n",
    "\n",
    "        # We have to loop over all our batches in every epoch\n",
    "        while True:\n",
    "            try:\n",
    "                # We train with one batch and read the summary and save it in the variable summary\n",
    "                _, summary = sess.run((training_step, merged_summaries))\n",
    "                \n",
    "                # We write the summary to the disk at the specified location\n",
    "                train_writer.add_summary(summary, global_steps)\n",
    "\n",
    "                # We update our step counter\n",
    "                global_steps += 1\n",
    "\n",
    "            # After we finished all batches, we catch the OutOfRangeError and break\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard loss screenshots\n",
    "\n",
    "- with outliers\n",
    "![](https://i.imgur.com/sH6N7kP.png)\n",
    "\n",
    "- without outliers\n",
    "![](https://i.imgur.com/oPXn11u.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
