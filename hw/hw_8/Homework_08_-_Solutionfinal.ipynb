{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "    \n",
    "training_data = read_idx('./MNIST/train-images-idx3-ubyte')\n",
    "training_labels = read_idx('./MNIST/train-labels-idx1-ubyte')\n",
    "\n",
    "# Normalize the training data.\n",
    "training_data = np.expand_dims(training_data, 3)\n",
    "print(training_data.shape)\n",
    "normalized_training_data = (training_data / 255) * 2 - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,10,figsize=(10,10))\n",
    "for i in range(10):\n",
    "    ax[i].imshow(training_data[i,:,:,0])\n",
    "    ax[i].axis('off')\n",
    "    ax[i].set_title(training_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters of the model.\n",
    "\n",
    "# We will train with batches of 64. Consisting out of 32 true images and 32 generated.\n",
    "generated_images_n = 32\n",
    "real_images_n = 32\n",
    "\n",
    "# The random noise vector will have dimension 50.\n",
    "z_dim = 50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Create the dataset.\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((normalized_training_data, training_labels))\n",
    "\n",
    "\n",
    "# Shuffle the training data in each iteration.\n",
    "training_dataset = training_dataset.shuffle(buffer_size = 60000)\n",
    "\n",
    "# Specify the batch sizes.\n",
    "training_dataset = training_dataset.batch(real_images_n, drop_remainder=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the iterator.\n",
    "iterator = tf.data.Iterator.from_structure(training_dataset.output_types,\n",
    "                                           training_dataset.output_shapes)\n",
    "\n",
    "# Name the operation that will give the next batch and name the \n",
    "# initialization operations.\n",
    "next_batch = iterator.get_next()\n",
    "training_init_op = iterator.make_initializer(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will define functions for the layers so our code is not redundant.\n",
    "\n",
    "def feed_forward_layer(x, hidden_n, activation_fn, normalize):        \n",
    "    initializer = tf.random_normal_initializer(stddev=0.02)\n",
    "\n",
    "    weights = tf.get_variable(\"weights\", [x.shape[1], hidden_n], tf.float32, initializer)\n",
    "    biases = tf.get_variable(\"biases\", [hidden_n], tf.float32, tf.zeros_initializer())\n",
    "    \n",
    "    drive = tf.matmul(x, weights) + biases\n",
    "    \n",
    "    if normalize:\n",
    "        drive = batch_norm(drive, [0])\n",
    "    \n",
    "    if activation_fn == 'linear':\n",
    "        return drive\n",
    "    else:\n",
    "        return activation_fn(drive)\n",
    "\n",
    "\n",
    "\n",
    "def conv_layer(x, kernels_n, kernel_size, stride_size, activation_fn, normalize):\n",
    "    initializer = tf.random_normal_initializer(stddev=0.02)\n",
    "    \n",
    "    kernels = tf.get_variable(\"kernels\", [kernel_size, kernel_size, x.shape[-1], kernels_n], tf.float32, initializer)\n",
    "    biases = tf.get_variable(\"biases\", [kernels_n], tf.float32, tf.zeros_initializer())\n",
    "\n",
    "    drive = tf.nn.conv2d(x, kernels, strides = [1, stride_size, stride_size, 1], padding = \"SAME\") + biases\n",
    "    \n",
    "    if normalize:\n",
    "        drive = batch_norm(drive, [0,1,2])\n",
    "    \n",
    "    return activation_fn(drive)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def back_conv_layer(x, target_shape, kernel_size, stride_size, activation_fn, normalize):\n",
    "    initializer = tf.random_normal_initializer(stddev=0.02)\n",
    "    \n",
    "    kernels = tf.get_variable(\"kernels\", [kernel_size, kernel_size, target_shape[-1], x.shape[-1]], tf.float32, initializer)\n",
    "    biases = tf.get_variable(\"biases\", [target_shape[-1]], tf.float32, tf.zeros_initializer())\n",
    "\n",
    "    drive = tf.nn.conv2d_transpose(x, kernels, target_shape, strides = [1, stride_size, stride_size, 1], padding = \"SAME\") + biases\n",
    "    \n",
    "    if normalize:\n",
    "        drive = batch_norm(drive, [0,1,2])\n",
    "    \n",
    "    return activation_fn(drive)\n",
    "\n",
    "\n",
    "def flatten(x):\n",
    "    size = int(np.prod(x.shape[1:]))\n",
    "    return tf.reshape(x, [-1, size])\n",
    "\n",
    "\n",
    "def batch_norm(x, axes):\n",
    "    mean, var = tf.nn.moments(x, axes = axes)\n",
    "    \n",
    "    offset_initializer = tf.constant_initializer(0.0)\n",
    "    offset = tf.get_variable(\"offset\", [x.shape[-1]], tf.float32, offset_initializer)\n",
    "    scale_initializer = tf.constant_initializer(1.0)\n",
    "    scale = tf.get_variable(\"scale\", [x.shape[-1]], tf.float32, scale_initializer)\n",
    "    \n",
    "    return tf.nn.batch_normalization(x, mean, var, offset, scale, 1e-6)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the generator network.\n",
    "z = tf.placeholder(tf.float32, [generated_images_n, z_dim])\n",
    "\n",
    "# generator network\n",
    "with tf.variable_scope(\"generator_layer_1\", reuse=tf.AUTO_REUSE):\n",
    "    gen_layer_1 = feed_forward_layer(z, 1024, tf.nn.relu, True)\n",
    "    gen_layer_1 = tf.reshape(gen_layer_1, [generated_images_n, 4, 4, 64])\n",
    "    \n",
    "    \n",
    "with tf.variable_scope(\"generator_layer_2\", reuse=tf.AUTO_REUSE):\n",
    "    gen_layer_2 = back_conv_layer(gen_layer_1, [generated_images_n, 7, 7, 32], 5, 2, tf.nn.relu, True)\n",
    "    \n",
    "with tf.variable_scope(\"generator_layer_3\", reuse=tf.AUTO_REUSE):\n",
    "    gen_layer_3 = back_conv_layer(gen_layer_2, [generated_images_n, 14, 14, 16], 5, 2, tf.nn.relu, True)    \n",
    "    \n",
    "with tf.variable_scope(\"generator_layer_4\", reuse=tf.AUTO_REUSE):\n",
    "    generated_images = back_conv_layer(gen_layer_3, [generated_images_n, 28, 28, 1], 5, 2, tf.nn.tanh, False)\n",
    "\n",
    " # get real images and concatenate real with generated   \n",
    "real_images = tf.cast(next_batch[0], dtype=tf.float32)\n",
    "real_and_generated_images = tf.concat([real_images, generated_images],0)\n",
    "\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"discriminator_layer_1\", reuse=tf.AUTO_REUSE):\n",
    "    dis_layer_1 = conv_layer(real_and_generated_images, 8, 5, 2, tf.nn.leaky_relu, True)\n",
    "    \n",
    "with tf.variable_scope(\"discriminator_layer_2\", reuse=tf.AUTO_REUSE):\n",
    "    dis_layer_2 = conv_layer(dis_layer_1, 16, 5, 2, tf.nn.leaky_relu, True)\n",
    "    \n",
    "with tf.variable_scope(\"discriminator_layer_3\", reuse=tf.AUTO_REUSE):\n",
    "    dis_layer_3 = conv_layer(dis_layer_2, 32, 5, 2, tf.nn.leaky_relu, True)\n",
    "    \n",
    "with tf.variable_scope(\"discriminator_layer_4\", reuse=tf.AUTO_REUSE):\n",
    "    flat = flatten(dis_layer_3)\n",
    "    logits = feed_forward_layer(flat, 1, \"linear\", True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d3b04c1d42cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# discriminator loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dis_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdis_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenerated_images_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreal_images_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdis_cross_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdis_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# we apply two losses one to the discriminator one to the generator\n",
    "\n",
    "# discriminator loss\n",
    "with tf.variable_scope(\"dis_loss\"):\n",
    "    dis_labels = tf.concat([tf.ones([generated_images_n,1]), tf.zeros([real_images_n,1])], axis=0)\n",
    "    dis_cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=dis_labels)\n",
    "    dis_loss = tf.reduce_mean(dis_cross_entropy)\n",
    "    \n",
    "# generator loss  \n",
    "with tf.variable_scope(\"gen_loss\"):\n",
    "    gen_labels = tf.ones([generated_images_n,1])\n",
    "    gen_cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits[generated_images_n:], labels=gen_labels)\n",
    "    gen_loss = tf.reduce_mean(gen_cross_entropy)\n",
    "    \n",
    "# get the generator and discriminator variables\n",
    "with tf.variable_scope(\"variables\"):\n",
    "    trainable_variables = tf.trainable_variables()\n",
    "    dis_variables = [var for var in trainable_variables if \"discriminator\" in var.name]\n",
    "    gen_variables = [var for var in trainable_variables if \"generator\" in var.name]\n",
    "\n",
    "    \n",
    "\n",
    "with tf.variable_scope(\"optimizer\", reuse=tf.AUTO_REUSE):\n",
    "    learning_rate = 0.0004\n",
    "    beta1 = 0.5\n",
    "    dis_optimizer = tf.train.AdamOptimizer(learning_rate, beta1 = beta1)\n",
    "    gen_optimizer = tf.train.AdamOptimizer(learning_rate, beta1 = beta1)\n",
    "\n",
    "    dis_training_step = dis_optimizer.minimize(dis_loss, var_list = dis_variables)\n",
    "    gen_training_step = gen_optimizer.minimize(gen_loss, var_list = gen_variables)    \n",
    "\n",
    "    \n",
    "tf.summary.scalar(\"dis_loss\", dis_loss)\n",
    "tf.summary.scalar(\"gen_loss\", gen_loss)\n",
    "merged_summaries = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"./summaries/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    global_step = 0\n",
    "    test_z = np.random.uniform(-1,1,[generated_images_n, z_dim]) \n",
    "\n",
    "    \n",
    "    for _ in range(2):\n",
    "        sess.run(training_init_op)\n",
    "        while True:\n",
    "            try:\n",
    "                z_values = np.random.uniform(-1,1,[generated_images_n, z_dim]) \n",
    "                summaries, _, _, = sess.run((merged_summaries,\n",
    "                                                 dis_training_step,\n",
    "                                                 gen_training_step),\n",
    "                                                 feed_dict={\n",
    "                                                     z: z_values                                                      \n",
    "\n",
    "                                                 })\n",
    "                \n",
    "                \n",
    "                test_images = sess.run((generated_images), feed_dict={z:test_z})\n",
    "                if global_step % 100 == 0:\n",
    "                    for i in range(generated_images_n):\n",
    "                        test_generated = test_images[i,:,:,0]\n",
    "                        test_generated = np.floor((test_generated + 1) * 0.5 * 255)\n",
    "                        im = Image.fromarray(test_generated)\n",
    "                        im = im.convert(\"L\")\n",
    "                        im.save(\"./images/{}_{}.png\".format(global_step,i))\n",
    "                writer.add_summary(summaries, global_step = global_step)\n",
    "                global_step += 1\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
